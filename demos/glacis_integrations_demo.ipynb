{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# GLACIS Integration Demo: Attestation for AI\n",
        "\n",
        "**What is GLACIS?** A library that creates tamper-proof receipts for AI operations.\n",
        "Prove what your AI did, what data it saw - without sensitive data leaving your environment.\n",
        "\n",
        "## What You'll Learn\n",
        "1. **Offline Mode** - Self-signed attestations, no API key needed\n",
        "2. **OpenAI Integration** - Automatic attestation for OpenAI API calls\n",
        "3. **Azure AI Integration** - Automatic attestation for Azure AI Inference calls\n",
        "\n",
        "## Core Concept: \"Hash Locally, Prove Globally\"\n",
        "- Input/output data is hashed locally (SHA-256)\n",
        "- Only hashes are transmitted, never actual payloads\n",
        "- Receipts are cryptographically signed (Ed25519)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup\n",
        "\n",
        "Install glacis with the integrations you need:\n",
        "\n",
        "```bash\n",
        "pip install glacis              # Core library\n",
        "pip install glacis[openai]      # OpenAI integration\n",
        "pip install glacis[azure]       # Azure AI Inference integration\n",
        "pip install glacis[openai,azure] # Both integrations\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "# Load environment variables from .env file if present\n",
        "try:\n",
        "    from dotenv import load_dotenv\n",
        "    load_dotenv()\n",
        "except ImportError:\n",
        "    pass\n",
        "\n",
        "# Generate a 32-byte signing seed for Ed25519\n",
        "# In production, persist this securely to maintain the same identity\n",
        "SIGNING_SEED = os.urandom(32)\n",
        "print(f\"Generated signing seed: {SIGNING_SEED.hex()[:16]}...\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 1. Offline Mode (No API Key Required)\n",
        "\n",
        "Perfect for development and testing. Receipts are self-signed and stored locally.\n",
        "Witness status will be `UNVERIFIED` until submitted to the transparency log."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from glacis import Glacis\n",
        "\n",
        "# Create an offline Glacis client\n",
        "glacis_offline = Glacis(mode=\"offline\", signing_seed=SIGNING_SEED)\n",
        "print(f\"Mode: {glacis_offline.mode}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Simulate an AI interaction\n",
        "prompt = \"What is the capital of France?\"\n",
        "response = \"The capital of France is Paris.\"\n",
        "\n",
        "# Create an attestation\n",
        "# Input and output are hashed locally, never sent anywhere\n",
        "receipt = glacis_offline.attest(\n",
        "    service_id=\"demo-app\",\n",
        "    operation_type=\"inference\",\n",
        "    input={\"prompt\": prompt},\n",
        "    output={\"response\": response},\n",
        "    metadata={\"model\": \"gpt-4\", \"temperature\": 0.7},\n",
        ")\n",
        "\n",
        "print(\"Attestation created!\")\n",
        "print(f\"  Receipt ID: {receipt.attestation_id}\")\n",
        "print(f\"  Payload Hash: {receipt.payload_hash}\")\n",
        "print(f\"  Signature: {receipt.signature[:40]}...\")\n",
        "print(f\"  Witness Status: {receipt.witness_status}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Verify the receipt\n",
        "result = glacis_offline.verify(receipt)\n",
        "\n",
        "print(\"Verification result:\")\n",
        "print(f\"  Signature Valid: {result.signature_valid}\")\n",
        "print(f\"  Overall Valid: {result.valid}\")\n",
        "print(f\"  Witness Status: {result.witness_status}\")\n",
        "\n",
        "# Receipts are stored locally at ~/.glacis/receipts.db\n",
        "print(f\"\\nReceipts stored in: ~/.glacis/receipts.db\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 2. Online Mode (API Key Required)\n",
        "\n",
        "For production use. Attestations are witnessed by the Glacis server and included in a Merkle tree.\n",
        "This provides third-party verifiability and tamper-evident logs.\n",
        "\n",
        "**Get your API key at https://glacis.io**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Set your API key (or set GLACIS_API_KEY environment variable)\n",
        "GLACIS_API_KEY = os.environ.get(\"GLACIS_API_KEY\", \"\")\n",
        "\n",
        "if not GLACIS_API_KEY:\n",
        "    print(\"No GLACIS_API_KEY found. Skipping online mode demo.\")\n",
        "    print(\"Set GLACIS_API_KEY environment variable or get a key at https://glacis.io\")\n",
        "    glacis_online = None\n",
        "else:\n",
        "    glacis_online = Glacis(api_key=GLACIS_API_KEY)\n",
        "    print(f\"Mode: {glacis_online.mode}\")\n",
        "    print(\"Online client ready!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if glacis_online:\n",
        "    # Create a witnessed attestation\n",
        "    online_receipt = glacis_online.attest(\n",
        "        service_id=\"demo-app\",\n",
        "        operation_type=\"inference\",\n",
        "        input={\"prompt\": \"What is 2 + 2?\"},\n",
        "        output={\"response\": \"4\"},\n",
        "    )\n",
        "    \n",
        "    print(\"Online attestation created!\")\n",
        "    print(f\"  Receipt ID: {online_receipt.attestation_id}\")\n",
        "    print(f\"  Leaf Index: {online_receipt.leaf_index}\")  # Position in Merkle tree\n",
        "    print(f\"  Badge URL: {online_receipt.badge_url}\")    # Shareable verification link\n",
        "    \n",
        "    # Access Merkle proof details if available\n",
        "    if online_receipt.receipt and online_receipt.receipt.transparency_proofs:\n",
        "        root_hash = online_receipt.receipt.transparency_proofs.sth_curr.root_hash\n",
        "        print(f\"  Merkle Root: {root_hash[:32]}...\")\n",
        "    \n",
        "    print(f\"  Witness Status: WITNESSED\")\n",
        "else:\n",
        "    print(\"Skipped - no API key\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 3. OpenAI Integration\n",
        "\n",
        "Automatically attest every OpenAI API call with a drop-in wrapper.\n",
        "\n",
        "**Requires:** `pip install glacis[openai]` and `OPENAI_API_KEY`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "OPENAI_API_KEY = os.environ.get(\"OPENAI_API_KEY\", \"\")\n",
        "\n",
        "try:\n",
        "    from glacis.integrations.openai import attested_openai, get_last_receipt as get_openai_receipt\n",
        "    openai_available = True\n",
        "except ImportError:\n",
        "    openai_available = False\n",
        "    print(\"OpenAI integration not installed. Run: pip install glacis[openai]\")\n",
        "\n",
        "if openai_available and not OPENAI_API_KEY:\n",
        "    print(\"No OPENAI_API_KEY found. Skipping OpenAI demo.\")\n",
        "    print(\"Set OPENAI_API_KEY environment variable to enable this section.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3a. OpenAI + Offline Attestation\n",
        "\n",
        "No GLACIS API key needed - receipts are signed locally."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if openai_available and OPENAI_API_KEY:\n",
        "    # Create an attested OpenAI client (offline mode)\n",
        "    openai_client_offline = attested_openai(\n",
        "        openai_api_key=OPENAI_API_KEY,\n",
        "        offline=True,\n",
        "        signing_seed=SIGNING_SEED,\n",
        "        service_id=\"openai-demo-offline\",\n",
        "    )\n",
        "    print(\"Attested OpenAI client ready (offline mode)!\")\n",
        "    \n",
        "    # Make an API call - attestation happens automatically\n",
        "    response = openai_client_offline.chat.completions.create(\n",
        "        model=\"gpt-4o-mini\",\n",
        "        messages=[{\"role\": \"user\", \"content\": \"What is 2 + 2? Answer in one word.\"}],\n",
        "        max_tokens=10,\n",
        "    )\n",
        "    \n",
        "    print(f\"\\nResponse: {response.choices[0].message.content}\")\n",
        "    \n",
        "    # Get the attestation receipt\n",
        "    openai_receipt_offline = get_openai_receipt()\n",
        "    print(f\"\\nAttestation created automatically!\")\n",
        "    print(f\"  Receipt ID: {openai_receipt_offline.attestation_id}\")\n",
        "    print(f\"  Payload Hash: {openai_receipt_offline.payload_hash}\")\n",
        "    print(f\"  Witness Status: {openai_receipt_offline.witness_status}\")\n",
        "else:\n",
        "    print(\"Skipped - OpenAI not available or no API key\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3b. OpenAI + Online Attestation\n",
        "\n",
        "Requires both GLACIS and OpenAI API keys. Receipts are witnessed by the GLACIS server."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if openai_available and OPENAI_API_KEY and GLACIS_API_KEY:\n",
        "    # Create an attested OpenAI client (online mode)\n",
        "    openai_client_online = attested_openai(\n",
        "        glacis_api_key=GLACIS_API_KEY,\n",
        "        openai_api_key=OPENAI_API_KEY,\n",
        "        service_id=\"openai-demo-online\",\n",
        "    )\n",
        "    print(\"Attested OpenAI client ready (online mode)!\")\n",
        "    \n",
        "    # Make an API call - attestation happens automatically\n",
        "    response = openai_client_online.chat.completions.create(\n",
        "        model=\"gpt-4o-mini\",\n",
        "        messages=[{\"role\": \"user\", \"content\": \"What is the square root of 16?\"}],\n",
        "        max_tokens=10,\n",
        "    )\n",
        "    \n",
        "    print(f\"\\nResponse: {response.choices[0].message.content}\")\n",
        "    \n",
        "    # Get the attestation receipt\n",
        "    openai_receipt_online = get_openai_receipt()\n",
        "    print(f\"\\nAttestation created automatically!\")\n",
        "    print(f\"  Receipt ID: {openai_receipt_online.attestation_id}\")\n",
        "    print(f\"  Leaf Index: {openai_receipt_online.leaf_index}\")\n",
        "    print(f\"  Badge URL: {openai_receipt_online.badge_url}\")\n",
        "    \n",
        "    # Access Merkle proof\n",
        "    if openai_receipt_online.receipt and openai_receipt_online.receipt.transparency_proofs:\n",
        "        root_hash = openai_receipt_online.receipt.transparency_proofs.sth_curr.root_hash\n",
        "        print(f\"  Merkle Root: {root_hash[:32]}...\")\n",
        "elif openai_available and OPENAI_API_KEY:\n",
        "    print(\"Skipped - no GLACIS_API_KEY. Set it for online attestation.\")\n",
        "else:\n",
        "    print(\"Skipped - OpenAI not available or no API keys\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 4. Azure AI Integration\n",
        "\n",
        "Automatically attest every Azure AI Inference call with a drop-in wrapper.\n",
        "\n",
        "**Requires:** `pip install glacis[azure]` and Azure credentials"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "AZURE_ENDPOINT = os.environ.get(\"AZURE_AI_ENDPOINT\", \"\")  # e.g., https://my-endpoint.inference.ai.azure.com\n",
        "AZURE_API_KEY = os.environ.get(\"AZURE_AI_API_KEY\", \"\")\n",
        "\n",
        "try:\n",
        "    from azure.ai.inference.models import UserMessage\n",
        "    from azure.core.credentials import AzureKeyCredential\n",
        "    from glacis.integrations.azure import attested_azure_inference, get_last_receipt as get_azure_receipt\n",
        "    azure_available = True\n",
        "except ImportError:\n",
        "    azure_available = False\n",
        "    print(\"Azure AI integration not installed. Run: pip install glacis[azure]\")\n",
        "\n",
        "if azure_available and (not AZURE_ENDPOINT or not AZURE_API_KEY):\n",
        "    print(\"No Azure credentials found. Skipping Azure AI demo.\")\n",
        "    print(\"Set AZURE_AI_ENDPOINT and AZURE_AI_API_KEY environment variables to enable this section.\")\n",
        "    print(\"Example: AZURE_AI_ENDPOINT=https://my-endpoint.inference.ai.azure.com\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4a. Azure AI + Offline Attestation\n",
        "\n",
        "No GLACIS API key needed - receipts are signed locally."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if azure_available and AZURE_ENDPOINT and AZURE_API_KEY:\n",
        "    # Create an attested Azure AI client (offline mode)\n",
        "    azure_client_offline = attested_azure_inference(\n",
        "        endpoint=AZURE_ENDPOINT,\n",
        "        credential=AzureKeyCredential(AZURE_API_KEY),\n",
        "        offline=True,\n",
        "        signing_seed=SIGNING_SEED,\n",
        "        service_id=\"azure-demo-offline\",\n",
        "    )\n",
        "    print(\"Attested Azure AI client ready (offline mode)!\")\n",
        "    \n",
        "    # Make an API call - attestation happens automatically\n",
        "    response = azure_client_offline.complete(\n",
        "        messages=[UserMessage(content=\"What is 3 + 3? Answer in one word.\")],\n",
        "        model=\"gpt-4o\",  # Adjust based on your deployment\n",
        "        max_tokens=10,\n",
        "    )\n",
        "    \n",
        "    print(f\"\\nResponse: {response.choices[0].message.content}\")\n",
        "    \n",
        "    # Get the attestation receipt\n",
        "    azure_receipt_offline = get_azure_receipt()\n",
        "    print(f\"\\nAttestation created automatically!\")\n",
        "    print(f\"  Receipt ID: {azure_receipt_offline.attestation_id}\")\n",
        "    print(f\"  Payload Hash: {azure_receipt_offline.payload_hash}\")\n",
        "    print(f\"  Witness Status: {azure_receipt_offline.witness_status}\")\n",
        "else:\n",
        "    print(\"Skipped - Azure AI not available or no credentials\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4b. Azure AI + Online Attestation\n",
        "\n",
        "Requires both GLACIS API key and Azure credentials. Receipts are witnessed by the GLACIS server."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if azure_available and AZURE_ENDPOINT and AZURE_API_KEY and GLACIS_API_KEY:\n",
        "    # Create an attested Azure AI client (online mode)\n",
        "    azure_client_online = attested_azure_inference(\n",
        "        glacis_api_key=GLACIS_API_KEY,\n",
        "        endpoint=AZURE_ENDPOINT,\n",
        "        credential=AzureKeyCredential(AZURE_API_KEY),\n",
        "        service_id=\"azure-demo-online\",\n",
        "    )\n",
        "    print(\"Attested Azure AI client ready (online mode)!\")\n",
        "    \n",
        "    # Make an API call - attestation happens automatically\n",
        "    response = azure_client_online.complete(\n",
        "        messages=[UserMessage(content=\"What is the capital of Japan?\")],\n",
        "        model=\"gpt-4o\",  # Adjust based on your deployment\n",
        "        max_tokens=20,\n",
        "    )\n",
        "    \n",
        "    print(f\"\\nResponse: {response.choices[0].message.content}\")\n",
        "    \n",
        "    # Get the attestation receipt\n",
        "    azure_receipt_online = get_azure_receipt()\n",
        "    print(f\"\\nAttestation created automatically!\")\n",
        "    print(f\"  Receipt ID: {azure_receipt_online.attestation_id}\")\n",
        "    print(f\"  Leaf Index: {azure_receipt_online.leaf_index}\")\n",
        "    print(f\"  Badge URL: {azure_receipt_online.badge_url}\")\n",
        "    \n",
        "    # Access Merkle proof\n",
        "    if azure_receipt_online.receipt and azure_receipt_online.receipt.transparency_proofs:\n",
        "        root_hash = azure_receipt_online.receipt.transparency_proofs.sth_curr.root_hash\n",
        "        print(f\"  Merkle Root: {root_hash[:32]}...\")\n",
        "elif azure_available and AZURE_ENDPOINT and AZURE_API_KEY:\n",
        "    print(\"Skipped - no GLACIS_API_KEY. Set it for online attestation.\")\n",
        "else:\n",
        "    print(\"Skipped - Azure AI not available or no credentials\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## Summary\n",
        "\n",
        "| Integration | Mode | API Keys Required | Witness Status |\n",
        "|------------|------|-------------------|----------------|\n",
        "| Core | Offline | None | `UNVERIFIED` |\n",
        "| Core | Online | GLACIS | `WITNESSED` |\n",
        "| OpenAI | Offline | OpenAI | `UNVERIFIED` |\n",
        "| OpenAI | Online | GLACIS + OpenAI | `WITNESSED` |\n",
        "| Azure AI | Offline | Azure | `UNVERIFIED` |\n",
        "| Azure AI | Online | GLACIS + Azure | `WITNESSED` |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### What's in a Receipt?\n",
        "\n",
        "**Offline Receipt (`OfflineAttestReceipt`):**\n",
        "- `attestation_id`: Unique identifier (`oatt_xxx`)\n",
        "- `payload_hash`: SHA-256 of canonical JSON (input + output)\n",
        "- `signature`: Ed25519 signature over the attestation\n",
        "- `timestamp`: When the attestation was created\n",
        "- `witness_status`: Always `UNVERIFIED`\n",
        "\n",
        "**Online Receipt (`AttestReceipt`):**\n",
        "- `attestation_id`: Unique identifier (`att_xxx`)\n",
        "- `attestation_hash`: Hash of the attestation content\n",
        "- `leaf_index`: Position in Merkle tree\n",
        "- `tree_size`: Tree size when receipt was issued\n",
        "- `badge_url`: Shareable verification link\n",
        "- `receipt.transparency_proofs`: Full Merkle inclusion proof"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Environment Variables Reference\n",
        "\n",
        "Create a `.env` file with these values:\n",
        "\n",
        "```bash\n",
        "# GLACIS (required for online attestation)\n",
        "GLACIS_API_KEY=glsk_live_xxx\n",
        "\n",
        "# OpenAI (required for OpenAI integration)\n",
        "OPENAI_API_KEY=sk-xxx\n",
        "\n",
        "# Azure AI (required for Azure integration)\n",
        "AZURE_AI_ENDPOINT=https://my-endpoint.inference.ai.azure.com\n",
        "AZURE_AI_API_KEY=xxx\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Next Steps\n",
        "\n",
        "1. **Get an API key** at https://glacis.io for production use\n",
        "2. **Explore the Anthropic integration**: `from glacis.integrations.anthropic import attested_anthropic`\n",
        "3. **Query the transparency log**: `glacis.query_log(org_id=\"...\", service_id=\"...\")`\n",
        "4. **Check stored receipts**: `~/.glacis/receipts.db` (SQLite)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cleanup\n",
        "glacis_offline.close()\n",
        "if glacis_online:\n",
        "    glacis_online.close()\n",
        "print(\"Done!\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
