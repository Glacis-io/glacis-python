{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": "# GLACIS Judge Pipeline Demo\n\nEnd-to-end: **attested QA generation** &rarr; **LLM judge review** &rarr; **human edit** &rarr; **re-judge** &rarr; **attestation chain**\n\nEvery LLM call goes through `attested_openai()` &mdash; the control pipeline (input/output staged PII scanning, jailbreak detection), evidence hashing, signing, and storage happen automatically.\n\n```bash\npip install glacis openai anthropic\n```\n\nSet `OPENAI_API_KEY` and `ANTHROPIC_API_KEY` in environment or `tests/.env`."
  },
  {
   "cell_type": "code",
   "id": "cell-1",
   "metadata": {},
   "source": "import json, os, sys\nfrom pathlib import Path\n\nREPO_ROOT = Path(\".\").resolve().parent\nif str(REPO_ROOT) not in sys.path:\n    sys.path.insert(0, str(REPO_ROOT))\n\n# Load .env\nenv_path = REPO_ROOT / \"tests\" / \".env\"\nif env_path.exists():\n    for line in env_path.read_text().splitlines():\n        line = line.strip()\n        if line and not line.startswith(\"#\") and \"=\" in line:\n            k, v = line.split(\"=\", 1)\n            os.environ.setdefault(k.strip(), v.strip())\n\nOPENAI_API_KEY = os.environ[\"OPENAI_API_KEY\"]\nANTHROPIC_API_KEY = os.environ[\"ANTHROPIC_API_KEY\"]\nSIGNING_SEED = b\"demo-pipeline-seed-0000000000000\"  # 32 bytes\n\nfrom glacis.integrations.openai import attested_openai, get_last_receipt\nfrom glacis import Glacis\nfrom glacis.config import load_config\nfrom glacis.storage import create_storage\nfrom glacis.judges import JudgeRunner\nfrom judges.qa_explain_judge import OpenAIJudge, AnthropicJudge\n\nconfig = load_config(\"glacis.yaml\")\n\n# Attested OpenAI client — controls + attestation built in\nclient = attested_openai(\n    openai_api_key=OPENAI_API_KEY,\n    signing_seed=SIGNING_SEED,\n    config=\"glacis.yaml\",\n)\n\n# Glacis client for chain operations (decompose, review, sampling)\nglacis = Glacis(\n    mode=\"offline\",\n    signing_seed=SIGNING_SEED,\n    storage_backend=config.evidence_storage.backend,\n    storage_path=Path(config.evidence_storage.path),\n    sampling_config=config.sampling,\n)\n\n# Evidence store for persisting full input/output payloads\nevidence_store = create_storage(\n    backend=config.evidence_storage.backend,\n    path=Path(config.evidence_storage.path),\n)\n\n# Judge runner (thresholds from glacis.yaml)\njudge_runner = JudgeRunner(\n    judges=[OpenAIJudge(api_key=OPENAI_API_KEY), AnthropicJudge(api_key=ANTHROPIC_API_KEY)],\n    config=config.judges,\n)\n\nprint(f\"Config:  {config.policy.id} | storage: {config.evidence_storage.backend}\")\nprint(f\"Sampling: L1={config.sampling.l1_rate}, L2={config.sampling.l2_rate}\")\nprint(f\"Judges:  uphold >= {config.judges.uphold_threshold}, borderline >= {config.judges.borderline_threshold}\")",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "cell-2",
   "metadata": {},
   "source": "## 1. Attested QA Generation\n\nSwap `OpenAI()` for `attested_openai()` &mdash; every LLM call is automatically attested with the staged control pipeline (input PII scanning + jailbreak detection, output controls), evidence hashing, and local signing. Zero changes to your prompt logic."
  },
  {
   "cell_type": "code",
   "id": "cell-3",
   "metadata": {},
   "source": "import re\n\nSOURCE_DOCUMENT = \"\"\"\nACME Health \\u2014 Patient Data Handling Policy (v2.1)\n\n1. All patient records must be encrypted at rest using AES-256.\n2. Access to PHI requires two-factor authentication (2FA).\n3. Data retention: patient records are kept for 7 years after last visit.\n4. De-identification follows the HIPAA Safe Harbor method (18 identifiers removed).\n5. Breach notification must occur within 72 hours of discovery.\n6. Business associates must sign a BAA before accessing any PHI.\n7. Minimum necessary standard: staff access only the PHI needed for their role.\n8. Audit logs of all PHI access are retained for 6 years.\n\"\"\".strip()\n\ndef parse_json_array(raw):\n    \"\"\"Extract a JSON array from an LLM response (handles markdown fences).\"\"\"\n    text = raw.strip()\n    if text.startswith(\"```\"):\n        text = text.split(\"\\n\", 1)[1] if \"\\n\" in text else text[3:]\n        if text.endswith(\"```\"):\n            text = text[:-3]\n        text = text.strip()\n    match = re.search(r\"\\[.*\\]\", text, re.DOTALL)\n    if match:\n        text = match.group()\n    return json.loads(text)\n\ndef parse_json_object(raw):\n    \"\"\"Extract a JSON object from an LLM response (handles markdown fences).\"\"\"\n    text = raw.strip()\n    if text.startswith(\"```\"):\n        text = text.split(\"\\n\", 1)[1] if \"\\n\" in text else text[3:]\n        if text.endswith(\"```\"):\n            text = text[:-3]\n        text = text.strip()\n    match = re.search(r\"\\{.*\\}\", text, re.DOTALL)\n    if match:\n        text = match.group()\n    return json.loads(text)\n\n# One call — PII scanning + attestation happen automatically\nresponse = client.chat.completions.create(\n    model=\"gpt-4o-mini\",\n    messages=[{\"role\": \"user\", \"content\": f\"\"\"Generate exactly 5 question-answer pairs from this document.\nEach pair tests factual knowledge. Include one pair with an intentionally wrong answer.\nReturn JSON array: [{{\"question\": \"...\", \"answer\": \"...\"}}]\n\nDocument:\n{SOURCE_DOCUMENT}\"\"\"}],\n    temperature=0.3,\n)\n\nreceipt = get_last_receipt()\nprint(f\"Attested: {receipt.id}\")\nprint(f\"  hash:      {receipt.evidence_hash[:32]}...\")\nprint(f\"  signature: {receipt.signature[:32]}...\")\nassert glacis.verify(receipt).valid\n\n# Parse QA pairs\nqa_pairs = parse_json_array(response.choices[0].message.content)\n\nprint(f\"\\n{len(qa_pairs)} QA pairs:\\n\")\nfor i, qa in enumerate(qa_pairs):\n    print(f\"  [{i}] Q: {qa['question']}\")\n    print(f\"      A: {qa['answer']}\\n\")",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "cell-4",
   "metadata": {},
   "source": "## 2. Decompose, Sample & Judge\n\nBreak the batch into individual attestations (shared `operation_id`), run deterministic L1 sampling, then score each pair with GPT-4o-mini + Claude Haiku judges."
  },
  {
   "cell_type": "code",
   "id": "cell-5",
   "metadata": {},
   "source": "# Decompose into individual QA pair attestations\nqa_attestations = glacis.decompose(\n    receipt, qa_pairs,\n    operation_type=\"qa_pair\",\n    source_data={\"source_document\": SOURCE_DOCUMENT},\n)\n\n# L1 sampling — deterministic, auditor-reproducible, rate from glacis.yaml\nfor att in qa_attestations:\n    assert glacis.should_review(att).level == \"L1\"  # l1_rate=1.0 in config\n\nprint(f\"{len(qa_attestations)} pairs decomposed, all sampled for L1 review\\n\")\n\n# Judge each pair + attest the review\nreviews = []\nseq = qa_attestations[-1].operation_sequence + 1\n\nfor i, (qa, qa_att) in enumerate(zip(qa_pairs, qa_attestations)):\n    result = judge_runner.run(item=qa, reference=SOURCE_DOCUMENT)\n\n    review_input = {\"qa_pair\": qa, \"reference\": SOURCE_DOCUMENT}\n    review_output = result.model_dump()\n\n    review_att = glacis.attest(\n        service_id=config.attestation.service_id,\n        operation_type=\"qa_review\",\n        input=review_input,\n        output=review_output,\n        operation_id=receipt.operation_id,\n        operation_sequence=seq + i,\n    )\n\n    # Store full review evidence (judge scores, explanations, recommendation)\n    evidence_store.store_evidence(\n        attestation_id=review_att.id,\n        attestation_hash=review_att.evidence_hash,\n        mode=\"offline\",\n        service_id=config.attestation.service_id,\n        operation_type=\"qa_review\",\n        timestamp=review_att.timestamp or 0,\n        input_data=review_input,\n        output_data=review_output,\n    )\n\n    reviews.append((qa, result, qa_att, review_att))\n    print(f\"  [{i}] {result.final_score:.1f}/{result.max_score:.0f}  {result.recommendation:>10}   {qa['question'][:55]}\")\n\nuphold = sum(1 for _, r, _, _ in reviews if r.recommendation == \"uphold\")\nescalate = sum(1 for _, r, _, _ in reviews if r.recommendation == \"escalate\")\nprint(f\"\\n  {uphold} upheld, {len(reviews) - uphold - escalate} borderline, {escalate} escalated\")",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "cell-6",
   "metadata": {},
   "source": "## 3. Human Edit & Re-Judge\n\nFind the lowest-scoring pair, correct it, re-attest with `supersedes` (revision chain), and re-judge to verify the fix."
  },
  {
   "cell_type": "code",
   "id": "cell-7",
   "metadata": {},
   "source": "# Find worst pair\nworst_i = min(range(len(reviews)), key=lambda i: reviews[i][1].final_score)\nworst_qa, worst_result, worst_att, _ = reviews[worst_i]\n\nprint(f\"Flagged [{worst_i}]: {worst_result.final_score}/{worst_result.max_score} ({worst_result.recommendation})\")\nprint(f\"  Q: {worst_qa['question']}\")\nprint(f\"  A: {worst_qa['answer']}\")\n\n# Generate correction (also attested automatically via attested_openai)\nfix = client.chat.completions.create(\n    model=\"gpt-4o-mini\",\n    messages=[{\"role\": \"user\", \"content\": f\"\"\"Correct this answer using ONLY the source document.\n\nQuestion: {worst_qa['question']}\nWrong answer: {worst_qa['answer']}\nSource: {SOURCE_DOCUMENT}\n\nReturn JSON: {{\"corrected_answer\": \"...\"}}\"\"\"}],\n    temperature=0.1,\n)\n\ncorrected = parse_json_object(fix.choices[0].message.content)[\"corrected_answer\"]\nedited_qa = {\"question\": worst_qa[\"question\"], \"answer\": corrected}\nprint(f\"  Corrected: {corrected}\")\n\n# Re-attest with supersedes (revision chain)\nnext_seq = reviews[-1][3].operation_sequence + 1\n\nedited_input = {\"source_document\": SOURCE_DOCUMENT}\nedited_att = glacis.attest(\n    service_id=config.attestation.service_id,\n    operation_type=\"qa_pair\",\n    input=edited_input,\n    output=edited_qa,\n    operation_id=receipt.operation_id,\n    operation_sequence=next_seq,\n    supersedes=worst_att.id,\n)\n\n# Store evidence for the edited pair\nevidence_store.store_evidence(\n    attestation_id=edited_att.id,\n    attestation_hash=edited_att.evidence_hash,\n    mode=\"offline\",\n    service_id=config.attestation.service_id,\n    operation_type=\"qa_pair\",\n    timestamp=edited_att.timestamp or 0,\n    input_data=edited_input,\n    output_data=edited_qa,\n)\n\n# Re-judge the corrected pair\nre_result = judge_runner.run(item=edited_qa, reference=SOURCE_DOCUMENT)\n\nre_review_input = {\"qa_pair\": edited_qa, \"reference\": SOURCE_DOCUMENT}\nre_review_output = re_result.model_dump()\n\nre_review_att = glacis.attest(\n    service_id=config.attestation.service_id,\n    operation_type=\"qa_review\",\n    input=re_review_input,\n    output=re_review_output,\n    operation_id=receipt.operation_id,\n    operation_sequence=next_seq + 1,\n)\n\n# Store evidence for the re-review\nevidence_store.store_evidence(\n    attestation_id=re_review_att.id,\n    attestation_hash=re_review_att.evidence_hash,\n    mode=\"offline\",\n    service_id=config.attestation.service_id,\n    operation_type=\"qa_review\",\n    timestamp=re_review_att.timestamp or 0,\n    input_data=re_review_input,\n    output_data=re_review_output,\n)\n\nprint(f\"\\nRe-judge: {re_result.final_score}/{re_result.max_score} ({re_result.recommendation})\")\nprint(f\"Improvement: {worst_result.final_score} -> {re_result.final_score}\")\nprint(f\"Chain: {edited_att.id[:22]}... --supersedes--> {worst_att.id[:22]}...\")",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "cell-8",
   "metadata": {},
   "source": "## 4. Attestation Chain\n\nEvery operation &mdash; generation, decomposition, review, edit, re-review &mdash; is linked in one attestation chain."
  },
  {
   "cell_type": "code",
   "id": "cell-9",
   "metadata": {},
   "source": "all_atts = (\n    [receipt] + qa_attestations\n    + [ra for _, _, _, ra in reviews]\n    + [edited_att, re_review_att]\n)\nall_atts.sort(key=lambda a: a.operation_sequence)\n\nprint(f\"Operation {receipt.operation_id}\\n\")\nprint(f\"{'Seq':<5} {'Type':<14} {'ID':<26} {'Supersedes'}\")\nprint(\"-\" * 75)\nfor att in all_atts:\n    sup = att.supersedes[:22] + \"...\" if att.supersedes else \"\"\n    print(f\"{att.operation_sequence:<5} {att.operation_type:<14} {att.id[:24]:<26} {sup}\")\n\nprint(f\"\\n{len(all_atts)} attestations, 1 operation\\n\")\n\n# Evidence storage summary (JSONL format — one line per record)\nevidence_base = Path(config.evidence_storage.path)\nfor name in [\"receipts.jsonl\", \"evidence.jsonl\"]:\n    p = evidence_base / name\n    if p.exists():\n        lines = [l for l in p.read_text().splitlines() if l.strip()]\n        print(f\"{name}: {len(lines)} records\")\n\nevidence_store.close()\nglacis.close()\njudge_runner.close()",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}